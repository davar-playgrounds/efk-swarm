# Ref: https://medium.com/redbox-techblog/building-an-open-data-platform-logging-with-fluentd-and-elasticsearch-4582de868398
#
# System Level Settings
# ------------------------------------------------------------------
# Things like log level, root directory, and workers to use
# https://docs.fluentd.org/v1.0/articles/system-config
#
<system>
  root_dir /etc/fluentd
  log_level info
  # How many workers to split work!
  workers 3
</system>

# Input Plugins - forward
# ------------------------------------------------------------------
# How will Fluentd collect data? In this case, we are listening for
# incoming logs forwarded to the port below. Refer to diagram
# showing
# https://docs.fluentd.org/v1.0/articles/input-plugin-overview
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  add_tag_prefix dev
  #<transport tls>
    #cert_path /etc/td-agent/certs/fluentd.crt
    #private_key_path /etc/td-agent/certs/fluentd.key
    #private_key_passphrase YOUR_PASSPHRASE
  #</transport>
</source>

# Input Plugins - http
# -----------------------------------------------------------------
# https://docs.fluentd.org/input/http#tips-&-tricks
# ex.)
# $ msgpack=`echo -e "\x81\xa3foo\xa3bar"`
# $ curl -X POST -d "$msgpack" -H 'Content-Type: application/msgpack' \
#  http://localhost:9880/app.log
<source>
  @type http
  port 9880
  bind 0.0.0.0
  body_size_limit 32m
  keepalive_timeout 10s
  cors_allow_origins ["*"]
</source>

# Output Plugins
# -----------------------------------------------------------------
# When a tag match is found based on the below match pattern, what
# should Fluentd do with the data? In our case below, send to
# Elasticsearch and Amazon S3
# https://docs.fluentd.org/v1.0/articles/output-plugin-overview

<match apache.*>
  @type copy
  # Send logs to elasticsearch
  <store>
    @type elasticsearch
    # Basic Auth and Connection info
    scheme http
    #ssl_version TLSv1_2
    host elasticsearch
    port 9200
    #user <redacted>
    #password <redacted>
    # Built in support for logstash format as well!
    logstash_format true
    logstash_dateformat %Y.%m.%d
    logstash_prefix apache
    # How to buffer events in terms of time, tag, and size
    <buffer tag, time>
      @type file
      queued_chunks_limit_size 4096
      flush_thread_count 32
      total_limit_size 1GB
      path /var/log/fluentd/es-buffer

      chunk_limit_size 64MB
      chunk_full_threshold 0.9
      timekey 300

      flush_mode interval
      flush_interval 60s
      timekey_wait 0
      flush_at_shutdown true
      flush_thread_interval 30.0
      overflow_action drop_oldest_chunk

      retry_type periodic
      retry_wait 75
      retry_randomize false
      retry_max_times 4
    </buffer>
    <secondary>
      @type secondary_file
      directory /var/log/fluentd/es-error
      basename apache.log
    </secondary>
    # Basic Retry functionality in the event of downstream issues
    reconnect_on_error true
    reload_on_failure true
    reload_connections false
    request_timeout 120s
    retry_max_times 3
  </store>

  # Send logs to S3 as well
  #<store>
    # @type s3
    # External compression library to help reduce load from Fluent
    #
    # store_as gzip
    # aws_key_id YOUR_AWS_KEY_ID
    # aws_sec_key YOUR_AWS_SECRET_KEY
    # Note: Ability to use environment variables!
    # s3_bucket "apache-#{ENV['DEV']}"
    # path "logs/%Y/%m/%d/%H/apache"
    #
    # How to buffer events in terms of time, tag, and size
    # <buffer tag, time>
        #@type file
        #path /var/log/fluentd/s3-buffer
        #timekey 3600
        #timekey_use_utc true
        #chunk_limit_size 256m
    # </buffer>
  #</store>
</match>
